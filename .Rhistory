stepsbydayi <- aggregate(steps ~ date, imputedD, sum)
hist(stepsbydayi$steps, main = paste("Total Steps Each Day"), col="blue", xlab="Number of Steps")
#Create Histogram to show difference.
hist(stepsbyday$steps, main = paste("Total Steps Each Day"), col="red", xlab="Number of Steps", add=T)
legend("topright", c("Imputed", "Non-imputed"), col=c("blue", "red"), lwd=10)
rmean.i <- mean(stepsbydayi$steps)
rmedian.i <- median(stepsbydayi$steps)
meandiff <- rmean.i - rmean
meddiff <- rmedian.i - rmedian
totaldiff <- sum(stepsbydayi$steps) - sum(stepsbyday$steps)
## Are there differences in activity patterns between weekdays and weekends?
weekdays <- c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday")
imputedD$dow = as.factor(ifelse(is.element(weekdays(as.Date(imputedD$date)),weekdays), "Weekday", "Weekend"))
stepsbyintervali <- aggregate(steps ~ interval + dow, imputedD, mean)
library(lattice)
xyplot(stepsbyintervali$steps ~ stepsbyintervali$interval|stepsbyintervali$dow, main="Average Steps per Day by Interval",xlab="Interval", ylab="Steps",layout=c(1,2), type="l")
---
title: "Reproducible Research: Peer Assessment 1"
output:
html_document:
keep_md: true
---
## Loading and preprocessing the data
setwd("C:/Users/Farzad/Dropbox/Data Science Toolbox/RepData_PeerAssessment1")
D = read.csv("activity.csv",header = TRUE, sep = ",")
## What is mean total number of steps taken per day?
stepsbyday <- aggregate(steps ~ date, D, sum)
hist(stepsbyday$steps, main = paste("Total Steps Each Day"), col="blue", xlab="Number of Steps")
rmean <- mean(stepsbyday$steps)
rmedian <- median(stepsbyday$steps)
## What is the average daily activity pattern?
stepsbyinterval <- aggregate(steps ~ interval, D, mean)
plot(stepsbyinterval$interval,stepsbyinterval$steps, type="l", xlab="Interval", ylab="Number of Steps",main="Average Number of Steps per Day by Interval")
maxinterval <- stepsbyinterval[which.max(stepsbyinterval$steps),1]
## Imputing missing values
incomplete <- sum(!complete.cases(D))
imputedD <- transform(D, steps = ifelse(is.na(D$steps), stepsbyinterval$steps[match(D$interval, stepsbyinterval$interval)], D$steps))
stepsbydayi <- aggregate(steps ~ date, imputedD, sum)
hist(stepsbydayi$steps, main = paste("Total Steps Each Day"), col="blue", xlab="Number of Steps")
#Create Histogram to show difference.
hist(stepsbyday$steps, main = paste("Total Steps Each Day"), col="red", xlab="Number of Steps", add=T)
legend("topright", c("Imputed", "Non-imputed"), col=c("blue", "red"), lwd=10)
rmean.i <- mean(stepsbydayi$steps)
rmedian.i <- median(stepsbydayi$steps)
meandiff <- rmean.i - rmean
meddiff <- rmedian.i - rmedian
totaldiff <- sum(stepsbydayi$steps) - sum(stepsbyday$steps)
## Are there differences in activity patterns between weekdays and weekends?
weekdays <- c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday")
imputedD$dow = as.factor(ifelse(is.element(weekdays(as.Date(imputedD$date)),weekdays), "Weekday", "Weekend"))
stepsbyintervali <- aggregate(steps ~ interval + dow, imputedD, mean)
library(lattice)
xyplot(stepsbyintervali$steps ~ stepsbyintervali$interval|stepsbyintervali$dow, main="Average Steps per Day by Interval",xlab="Interval", ylab="Steps",layout=c(1,2), type="l")
install.packages("knitr")
knitr("PA_1_template")
knit2html("PA_1_template")
? knitr
??knitr
load(knitr)
library(knitr)
library("knitr")
install.packages(knitr)
install.packages("knitr")
library(knitr)
knit2html("PA_1_template")
dir()
knit2html("PA_1_template,Rmd")
knit2html("PA1_template.Rmd")
rmarkdown
install.packages("rmarkdown")
library(rmarkdown)
render("PA1_template.Rmd")
---
title: "Reproducible Research: Peer Assessment 1"
output:
html_document:
keep_md: true
---
## Loading and preprocessing the data
setwd("C:/Users/Farzad/Dropbox/Data Science Toolbox/RepData_PeerAssessment1")
D = read.csv("activity.csv",header = TRUE, sep = ",")
## What is mean total number of steps taken per day?
stepsbyday <- aggregate(steps ~ date, D, sum)
hist(stepsbyday$steps, main = paste("Total Steps Each Day"), col="blue", xlab="Number of Steps")
rmean <- mean(stepsbyday$steps)
rmedian <- median(stepsbyday$steps)
## What is the average daily activity pattern?
stepsbyinterval <- aggregate(steps ~ interval, D, mean)
plot(stepsbyinterval$interval,stepsbyinterval$steps, type="l", xlab="Interval", ylab="Number of Steps",main="Average Number of Steps per Day by Interval")
maxinterval <- stepsbyinterval[which.max(stepsbyinterval$steps),1]
## Imputing missing values
incomplete <- sum(!complete.cases(D))
imputedD <- transform(D, steps = ifelse(is.na(D$steps), stepsbyinterval$steps[match(D$interval, stepsbyinterval$interval)], D$steps))
stepsbydayi <- aggregate(steps ~ date, imputedD, sum)
hist(stepsbydayi$steps, main = paste("Total Steps Each Day"), col="blue", xlab="Number of Steps")
#Create Histogram to show difference.
hist(stepsbyday$steps, main = paste("Total Steps Each Day"), col="red", xlab="Number of Steps", add=T)
legend("topright", c("Imputed", "Non-imputed"), col=c("blue", "red"), lwd=10)
rmean.i <- mean(stepsbydayi$steps)
rmedian.i <- median(stepsbydayi$steps)
meandiff <- rmean.i - rmean
meddiff <- rmedian.i - rmedian
totaldiff <- sum(stepsbydayi$steps) - sum(stepsbyday$steps)
## Are there differences in activity patterns between weekdays and weekends?
weekdays <- c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday")
imputedD$dow = as.factor(ifelse(is.element(weekdays(as.Date(imputedD$date)),weekdays), "Weekday", "Weekend"))
stepsbyintervali <- aggregate(steps ~ interval + dow, imputedD, mean)
library(lattice)
xyplot(stepsbyintervali$steps ~ stepsbyintervali$interval|stepsbyintervali$dow, main="Average Steps per Day by Interval",xlab="Interval", ylab="Steps",layout=c(1,2), type="l")
install.packages("streamR")
library(streamR)
## Loading required package: RCurl
## Loading required package: bitops
## Loading required package: rjson
load("my_oauth")
filterStream("tweets.json", track = c("Obama", "Biden"), timeout = 10,
oauth = my_oauth)
## Loading required package: ROAuth
## Loading required package: digest
## Capturing tweets...
## Connection to Twitter stream was closed after 120 seconds with 1321 kB received.
tweets.df <- parseTweets("tweets.json", simplify = TRUE)
## 803 tweets have been parsed.
library(streamR)
load("my_oauth")
library(httr)
library(jsonlite)
myapp = oauth_app("twitter",key = "Vc28BAHOt1WAs1ADnQ0vuonZc", secret = "K0e2kEtG5AXNnr3nZLZFuRNRtPk6QV85jwo9G4s1HTw43Kcehs")
sig = sign_oauth1.0(myapp,token ="602004752-rzzQRGMNWP6uT6YsiGZwpeFOGda8mbNQtVn9MjWy", token_secret = "qWum7kewzD0SlS8pGLUNiz5wH6slUvJ5ea34SrYDVWrjK")
json2$statuses[5]
json1 = content(homeTL)
json2 = jsonlite::fromJSON(toJSON(json1))
library(httr)
library(jsonlite)
myapp = oauth_app("twitter",key = "Vc28BAHOt1WAs1ADnQ0vuonZc", secret = "K0e2kEtG5AXNnr3nZLZFuRNRtPk6QV85jwo9G4s1HTw43Kcehs")
sig = sign_oauth1.0(myapp,token ="602004752-rzzQRGMNWP6uT6YsiGZwpeFOGda8mbNQtVn9MjWy", token_secret = "qWum7kewzD0SlS8pGLUNiz5wH6slUvJ5ea34SrYDVWrjK")
homeTL = GET("https://api.twitter.com/1.1/search/tweets.json?q=%23boston&src=tyah",sig)
json1 = content(homeTL)
json2 = jsonlite::fromJSON(toJSON(json1))
json2$statuses[5]
load("my_oauth")
filterStream("tweets.json", track = c("Obama", "Biden"), timeout = 10,
oauth = my_oauth)
library(ROAuth)
install.packages("ROAuth")
library(ROAuth)
requestURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "https://api.twitter.com/oauth/access_token"
authURL <- "https://api.twitter.com/oauth/authorize"
consumerSecret <- "K0e2kEtG5AXNnr3nZLZFuRNRtPk6QV85jwo9G4s1HTw43Kcehs"
my_oauth <- OAuthFactory$new(consumerKey = consumerKey, consumerSecret = consumerSecret,
requestURL = requestURL, accessURL = accessURL, authURL = authURL)
consumerKey <- "Vc28BAHOt1WAs1ADnQ0vuonZc"
consumerSecret <- "K0e2kEtG5AXNnr3nZLZFuRNRtPk6QV85jwo9G4s1HTw43Kcehs"
my_oauth <- OAuthFactory$new(consumerKey = consumerKey, consumerSecret = consumerSecret,
requestURL = requestURL, accessURL = accessURL, authURL = authURL)
my_oauth$handshake(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl"))
my_oauth$handshake(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl"))
my_oauth$handshake(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl"))
save(my_oauth, file = "my_oauth.Rdata")
my_oauth$handshake(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl"))
save(my_oauth, file = "my_oauth.Rdata")
library(streamR)
## Loading required package: RCurl
## Loading required package: bitops
## Loading required package: rjson
load("my_oauth")
filterStream("tweets.json", track = c("Obama", "Biden"), timeout = 10,
oauth = my_oauth)
## Loading required package: ROAuth
## Loading required package: digest
## Capturing tweets...
## Connection to Twitter stream was closed after 120 seconds with 1321 kB received.
tweets.df <- parseTweets("tweets.json", simplify = TRUE)
## 803 tweets have been parsed.
dir()
load("my_oauth.Rdata")
filterStream("tweets.json", track = c("Obama", "Biden"), timeout = 10,
oauth = my_oauth)
## Loading required package: ROAuth
## Loading required package: digest
## Capturing tweets...
## Connection to Twitter stream was closed after 120 seconds with 1321 kB received.
tweets.df <- parseTweets("tweets.json", simplify = TRUE)
## 803 tweets have been parsed.
load("my_oauth.Rdata")
filterStream("tweets.json", track = c("Obama", "Biden"), timeout = 10,
oauth = my_oauth)
filterStream("tweets.json", track = c("Obama", "Biden"), timeout = 100,
oauth = my_oauth)
tweets.df <- parseTweets("tweets.json", simplify = TRUE)
library(streamR)
## Loading required package: RCurl
## Loading required package: bitops
## Loading required package: rjson
load("my_oauth.Rdata")
filterStream("tweets.json", track = c("Obama", "Biden"), timeout = 100,
oauth = my_oauth)
## Loading required package: ROAuth
## Loading required package: digest
## Capturing tweets...
## Connection to Twitter stream was closed after 120 seconds with 1321 kB received.
tweets.df <- parseTweets("tweets.json", simplify = TRUE)
## 803 tweets have been parsed.
load("my_oauth.Rdata")
my_oauth
filterStream("tweets.json", track = c("Obama", "Biden"), timeout = 10,
oauth = my_oauth)
tweets.df <- parseTweets("tweets.json", simplify = TRUE)
dir()
tweets.json
head(tweets.json)
my_oauth <- OAuthFactory$new(consumerKey = consumerKey, consumerSecret = consumerSecret,
requestURL = requestURL, accessURL = accessURL, authURL = authURL)
my_oauth$handshake(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl"))
save(my_oauth, file = "my_oauth.Rdata")
load("my_oauth.Rdata")
filterStream("tweets.json", track = c("Obama", "Biden"), timeout = 10,
oauth = my_oauth)
library(ROAuth)
requestURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "https://api.twitter.com/oauth/access_token"
authURL <- "https://api.twitter.com/oauth/authorize"
consumerKey <- "Vc28BAHOt1WAs1ADnQ0vuonZc"
consumerSecret <- "K0e2kEtG5AXNnr3nZLZFuRNRtPk6QV85jwo9G4s1HTw43Kcehs"
my_oauth <- OAuthFactory$new(consumerKey = consumerKey, consumerSecret = consumerSecret,
requestURL = requestURL, accessURL = accessURL, authURL = authURL)
my_oauth$handshake(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl"))
library(ROAuth)
requestURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "https://api.twitter.com/oauth/access_token"
authURL <- "https://api.twitter.com/oauth/authorize"
consumerKey <- "Vc28BAHOt1WAs1ADnQ0vuonZc"
consumerSecret <- "K0e2kEtG5AXNnr3nZLZFuRNRtPk6QV85jwo9G4s1HTw43Kcehs"
my_oauth <- OAuthFactory$new(consumerKey = consumerKey, consumerSecret = consumerSecret,
requestURL = requestURL, accessURL = accessURL, authURL = authURL)
my_oauth$handshake(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl"))
save(my_oauth, file = "my_oauth.Rdata")
load("my_oauth.Rdata")
filterStream("tweets.json", track = c("Obama", "Biden"), timeout = 10,
oauth = my_oauth)
filterStream( file.name="tweets_rstats.json",track="Landon Donovan", tweets=10, oauth=cred)
filterStream( file.name="tweets_rstats.json",track="Landon Donovan", tweets=10, oauth=my_oauth)
library(ROAuth)
reqURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "http://api.twitter.com/oauth/access_token"
authURL <- "http://api.twitter.com/oauth/authorize"
consumerKey <- "Vc28BAHOt1WAs1ADnQ0vuonZc"
consumerSecret <- "K0e2kEtG5AXNnr3nZLZFuRNRtPk6QV85jwo9G4s1HTw43Kcehs"
my_oauth <- OAuthFactory$new(consumerKey=consumerKey,
consumerSecret=consumerSecret,
requestURL=reqURL,
accessURL=accessURL,
authURL=authURL)
my_oauth$handshake()
timeout=3600, oauth=my_oauth )
tweets.df <- parseTweets("my_timeline.json")
library(ROAuth)
reqURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "http://api.twitter.com/oauth/access_token"
authURL <- "http://api.twitter.com/oauth/authorize"
consumerKey <- "Vc28BAHOt1WAs1ADnQ0vuonZc"
consumerSecret <- "K0e2kEtG5AXNnr3nZLZFuRNRtPk6QV85jwo9G4s1HTw43Kcehs"
my_oauth <- OAuthFactory$new(consumerKey=consumerKey,
consumerSecret=consumerSecret,
requestURL=reqURL,
accessURL=accessURL,
authURL=authURL)
my_oauth$handshake()
userStream( file="my_timeline.json", with="followings",
timeout=3600, oauth=my_oauth )
my_oauth$handshake()
## Not run:
## The following example shows how to capture a user's home timeline
## with the Streaming API and using authentication via the ROAuth
## package, with fictitious consumerkey and consumer secret.
## You can obtain your own at dev.twitter.com
library(ROAuth)
requestURL <- "https://api.twitter.com/oauth/request_token"
userStream 11
accessURL <- "http://api.twitter.com/oauth/access_token"
authURL <- "http://api.twitter.com/oauth/authorize"
consumerKey <- "Vc28BAHOt1WAs1ADnQ0vuonZc"
consumerSecret <- "K0e2kEtG5AXNnr3nZLZFuRNRtPk6QV85jwo9G4s1HTw43Kcehs"
my_oauth <- OAuthFactory$new(consumerKey=consumerKey,
consumerSecret=consumerSecret, requestURL=requestURL,
accessURL=accessURL, authURL=authURL)
my_oauth$handshake(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl"))
library(ROAuth)
requestURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "https://api.twitter.com/oauth/access_token"
authURL <- "https://api.twitter.com/oauth/authorize"
consumerKey <- "Vc28BAHOt1WAs1ADnQ0vuonZc"
consumerSecret <- "K0e2kEtG5AXNnr3nZLZFuRNRtPk6QV85jwo9G4s1HTw43Kcehs"
my_oauth <- OAuthFactory$new(consumerKey = consumerKey, consumerSecret = consumerSecret,
requestURL = requestURL, accessURL = accessURL, authURL = authURL)
my_oauth$handshake(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl"))
my_oauth$handshake()
timeout=3600, oauth=my_oauth )
tweets.df <- parseTweets("my_timeline.json")
authURL=authURL)
my_oauth$handshake()
userStream( file.name="my_timeline.json", with="followings",
tweets=10, oauth=my_oauth )
userStream( file.name="my_timeline.json", with="followings",
tweets=10, oauth=my_oauth )
userStream( file.name="my_timeline.json", with="followings",
tweets=10, oauth=my_oauth )
userStream( file.name="my_timeline.json", with="followings",
tweets=10, oauth=my_oauth )
userStream( file.name="my_timeline.json", with="followings",
tweets=10, oauth=my_oauth )
userStream( file.name="my_timeline.json", with="followings",
tweets=10, oauth=my_oauth )
userStream( file="my_timeline.json", with="followings",
timeout=3600, oauth=my_oauth )
tweets.df <- parseTweets("my_timeline.json")
json1 = content(homeTL)
json2 = jsonlite::fromJSON(toJSON(json1))
json2$statuses[5]
curl --get 'https://api.twitter.com/1.1/' --header 'Authorization: OAuth oauth_consumer_key="Vc28BAHOt1WAs1ADnQ0vuonZc", oauth_nonce="652d59a3c760190e41eac39afbbe0004", oauth_signature="QPIeURZlIHJsO9Zjt97XDxLUw8M%3D", oauth_signature_method="HMAC-SHA1", oauth_timestamp="1458008933", oauth_token="602004752-rzzQRGMNWP6uT6YsiGZwpeFOGda8mbNQtVn9MjWy", oauth_version="1.0"' --verbose
curl --get 'https://api.twitter.com/1.1/' --header 'Authorization: OAuth
userStream( file="my_timeline.json", with="followings",
timeout=3600, oauth=my_oauth )
library(devtools)
install_github("streamR", "pablobarbera", subdir="streamR")
install.packages("streamR")  # from CRAN
library(devtools)
install_github("streamR", "pablobarbera", subdir = "streamR")  # from GitHub
library(devtools)
install_github("streamR", "pablobarbera", subdir="streamR")
install.packages("streamR")  # from CRAN
library(devtools)
install_github("streamR", "pablobarbera", subdir = "streamR")  # from GitHub
install.packages("streamR")
library(ROAuth)
requestURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "https://api.twitter.com/oauth/access_token"
authURL <- "https://api.twitter.com/oauth/authorize"
authURL <- "https://api.twitter.com/oauth/authorize"
consumerKey <- "Vc28BAHOt1WAs1ADnQ0vuonZc"
my_oauth <- OAuthFactory$new(consumerKey = consumerKey, consumerSecret = consumerSecret,
requestURL = requestURL, accessURL = accessURL, authURL = authURL)
my_oauth$handshake(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl"))
save(my_oauth, file = "my_oauth.Rdata")
library(streamR)
load("my_oauth.Rdata")
filterStream("tweets.json", track = c("Obama", "Biden"), timeout = 120,
oauth = my_oauth)
tweets.df <- parseTweets("tweets.json", simplify = TRUE)
c( length(grep("obama", tweets.df$text, ignore.case = TRUE)),
length(grep("biden", tweets.df$text, ignore.case = TRUE)) )
lterStream("tweetsUS.json", locations = c(-125, 25, -66, 50), timeout = 300,
oauth = my_oauth)
tweets.df <- parseTweets("tweetsUS.json", verbose = FALSE)
library(ggplot2)
library(grid)
map.data <- map_data("state")
points <- data.frame(x = as.numeric(tweets.df$lon), y = as.numeric(tweets.df$lat))
points <- points[points$y > 25, ]
ggplot(map.data) + geom_map(aes(map_id = region), map = map.data, fill = "white",
color = "grey20", size = 0.25) + expand_limits(x = map.data$long, y = map.data$lat) +
theme(axis.line = element_blank(), axis.text = element_blank(), axis.ticks = element_blank(),
axis.title = element_blank(), panel.background = element_blank(), panel.border = element_blank(),
panel.grid.major = element_blank(), plot.background = element_blank(),
plot.margin = unit(0 * c(-1.5, -1.5, -1.5, -1.5), "lines")) + geom_point(data = points,
aes(x = x, y = y), size = 1, alpha = 1/5, color = "darkblue")
library(ggplot2)
library(grid)
map.data <- map_data("state")
install.packages("maps")
library(maps)
map.data <- map_data("state")
save(my_oauth, file = "my_oauth.Rdata")
map.data <- map_data("state")
points <- data.frame(x = as.numeric(tweets.df$lon), y = as.numeric(tweets.df$lat))
points <- points[points$y > 25, ]
ggplot(map.data) + geom_map(aes(map_id = region), map = map.data, fill = "white",
color = "grey20", size = 0.25) + expand_limits(x = map.data$long, y = map.data$lat) +
theme(axis.line = element_blank(), axis.text = element_blank(), axis.ticks = element_blank(),
axis.title = element_blank(), panel.background = element_blank(), panel.border = element_blank(),
panel.grid.major = element_blank(), plot.background = element_blank(),
plot.margin = unit(0 * c(-1.5, -1.5, -1.5, -1.5), "lines")) + geom_point(data = points,
aes(x = x, y = y), size = 1, alpha = 1/5, color = "darkblue")
tweets.df
ggplot(map.data) + geom_map(aes(map_id = region), map = map.data, fill = "white",
color = "grey20", size = 0.25) + expand_limits(x = map.data$long, y = map.data$lat) +
theme(axis.line = element_blank(), axis.text = element_blank(), axis.ticks = element_blank(),
axis.title = element_blank(), panel.background = element_blank(), panel.border = element_blank(),
panel.grid.major = element_blank(), plot.background = element_blank(),
plot.margin = unit(0 * c(-1.5, -1.5, -1.5, -1.5), "lines")) + geom_point(data = points,
aes(x = x, y = y), size = 1, alpha = 1/5, color = "darkblue")
points <- data.frame(x = as.numeric(tweets.df$lon), y = as.numeric(tweets.df$lat))
points
tweets.df
names(tweets.df)
tweets.df$location
head(tweets.df)
tweets.df$lat
library(ggplot2)
library(grid)
map.data <- map_data("state")
points <- data.frame(x = as.numeric(tweets.df$lon), y = as.numeric(tweets.df$lat))
points <- points[points$y > 25, ]
ggplot(map.data) + geom_map(aes(map_id = region), map = map.data, fill = "white",
color = "grey20", size = 0.25) + expand_limits(x = map.data$long, y = map.data$lat) +
theme(axis.line = element_blank(), axis.text = element_blank(), axis.ticks = element_blank(),
axis.title = element_blank(), panel.background = element_blank(), panel.border = element_blank(),
panel.grid.major = element_blank(), plot.background = element_blank(),
plot.margin = unit(0 * c(-1.5, -1.5, -1.5, -1.5), "lines")) + geom_point(data = points,
aes(x = x, y = y), size = 1, alpha = 1/5, color = "darkblue")
lterStream("tweetsUS.json", timeout = 300,
oauth = my_oauth)
tweets.df <- parseTweets("tweetsUS.json", verbose = FALSE)
tweets.df <- parseTweets("tweets.json", simplify = TRUE)
names(tweets.df)
tweets.df$lat
filterStream("tweetsUS.json", locations = c(-125, 25, -66, 50), timeout = 300,
oauth = my_oauth)
tweets.df <- parseTweets("tweetsUS.json", verbose = FALSE)
names(tweets.df)
library(ggplot2)
library(grid)
map.data <- map_data("state")
points <- data.frame(x = as.numeric(tweets.df$lon), y = as.numeric(tweets.df$lat))
points <- points[points$y > 25, ]
ggplot(map.data) + geom_map(aes(map_id = region), map = map.data, fill = "white",
color = "grey20", size = 0.25) + expand_limits(x = map.data$long, y = map.data$lat) +
theme(axis.line = element_blank(), axis.text = element_blank(), axis.ticks = element_blank(),
axis.title = element_blank(), panel.background = element_blank(), panel.border = element_blank(),
panel.grid.major = element_blank(), plot.background = element_blank(),
plot.margin = unit(0 * c(-1.5, -1.5, -1.5, -1.5), "lines")) + geom_point(data = points,
aes(x = x, y = y), size = 1, alpha = 1/5, color = "darkblue")
summary(tweets.df)
#### This script uses RCurl and RJSONIO to download data from Google's API:
#### Latitude, longitude, location type (see explanation at the end), formatted address
#### Notice ther is a limit of 2,500 calls per day
library(RCurl)
library(RJSONIO)
library(plyr)
url <- function(address, return.call = "json", sensor = "false") {
root <- "http://maps.google.com/maps/api/geocode/"
u <- paste(root, return.call, "?address=", address, "&sensor=", sensor, sep = "")
return(URLencode(u))
}
geoCode <- function(address,verbose=FALSE) {
if(verbose) cat(address,"\n")
u <- url(address)
doc <- getURL(u)
x <- fromJSON(doc,simplify = FALSE)
if(x$status=="OK") {
lat <- x$results[[1]]$geometry$location$lat
lng <- x$results[[1]]$geometry$location$lng
location_type <- x$results[[1]]$geometry$location_type
formatted_address <- x$results[[1]]$formatted_address
return(c(lat, lng, location_type, formatted_address))
} else {
return(c(NA,NA,NA, NA))
}
}
install.packages("RJSONIO")
library(RCurl)
library(RJSONIO)
library(plyr)
url <- function(address, return.call = "json", sensor = "false") {
root <- "http://maps.google.com/maps/api/geocode/"
u <- paste(root, return.call, "?address=", address, "&sensor=", sensor, sep = "")
return(URLencode(u))
}
geoCode <- function(address,verbose=FALSE) {
if(verbose) cat(address,"\n")
u <- url(address)
doc <- getURL(u)
x <- fromJSON(doc,simplify = FALSE)
if(x$status=="OK") {
lat <- x$results[[1]]$geometry$location$lat
lng <- x$results[[1]]$geometry$location$lng
location_type <- x$results[[1]]$geometry$location_type
formatted_address <- x$results[[1]]$formatted_address
return(c(lat, lng, location_type, formatted_address))
} else {
return(c(NA,NA,NA, NA))
}
}
address <- geoCode("The White House, Washington, DC")
url <- function(address, return.call = "json", sensor = "false") {
root <- "http://maps.google.com/maps/api/geocode/"
u <- paste(root, return.call, "?address=", address, "&sensor=", sensor, sep = "")
return(URLencode(u))
}
geoCode <- function(address,verbose=FALSE) {
if(verbose) cat(address,"\n")
u <- url(address)
doc <- getURL(u)
x <- fromJSON(doc,simplify = FALSE)
if(x$status=="OK") {
lat <- x$results[[1]]$geometry$location$lat
lng <- x$results[[1]]$geometry$location$lng
location_type <- x$results[[1]]$geometry$location_type
formatted_address <- x$results[[1]]$formatted_address
return(c(lat, lng, location_type, formatted_address))
} else {
return(c(NA,NA,NA, NA))
}
}
locations <- ldply(address, function(x) geoCode(x))
names(locations) <- c("lat","lon","location_type", "forAddress")
locations
address <- geoCode(" 3207 Woodvalley Dr. Pikesville MD 21208")
locations <- ldply(address, function(x) geoCode(x))
names(locations) <- c("lat","lon","location_type", "forAddress")
locations
